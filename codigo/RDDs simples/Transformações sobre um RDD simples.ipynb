{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todos os comandos podem ser estudados na pagina oficial:\n",
    "# https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#rdd-persistence\n",
    "\n",
    "# a função de mapear (map) aplica uma função aos elementos de um RDD\n",
    "# Añade 1 a cada elemento del RDD\n",
    "# Para cada elemento, obtiene una tupla(x, x**2)\n",
    "\n",
    "rdd = sc.parallelize(xrange(-5,5))\n",
    "filtered_rdd = rdd.filter(lambda x : x >= 0)\n",
    "\n",
    "def add1(x):\n",
    "    return(x+1)\n",
    "\n",
    "squared_rdd = (filtered_rdd.map(add1).map(lambda x: (x, x*x)))\n",
    "\n",
    "squared_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 4, 3, 9, 4, 16, 5, 25]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora usando o flatMap\n",
    "# ele não devolve uma lista de listas como o map,\n",
    "# ao invez disso ele devolve uma unica lista\n",
    "\n",
    "rdd2 = sc.parallelize(xrange(-5,5))\n",
    "filtered_rdd2 = rdd.filter(lambda x : x >= 0)\n",
    "\n",
    "def add1(x):\n",
    "    return(x+1)\n",
    "\n",
    "squared_rdd2 = (filtered_rdd2.map(add1).flatMap(lambda x: (x, x*x)))\n",
    "\n",
    "squared_rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 4, 1, 25, 5, 9, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# retornando elementos uma unica vez cada\n",
    "# function distinct\n",
    "\n",
    "distinct_rdd = squared_rdd2.distinct()\n",
    "print(distinct_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[(0, <pyspark.resultiterable.ResultIterable object at 0x7f985393e7d0>), (1, <pyspark.resultiterable.ResultIterable object at 0x7f98313f2810>), (2, <pyspark.resultiterable.ResultIterable object at 0x7f98314ed550>)]\n",
      "\n",
      "\n",
      "[(0, [3, 9]), (1, [1, 4, 16, 25]), (2, [2, 5])]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy() devolve um RDD com os dados agrupados em formato chave/valor, usando uma função para obter a chave\n",
    "# sugestão o rendimento dessa função fica melhor se usado após um distinct\n",
    "\n",
    "grouped_rdd = distinct_rdd.groupBy(lambda x : x % 3)\n",
    "print(\"\\n\")\n",
    "print((grouped_rdd.collect()))\n",
    "print(\"\\n\")\n",
    "print([(x,sorted(y)) for (x,y) in grouped_rdd.collect() ])\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
